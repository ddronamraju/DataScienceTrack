{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why are the best and most experienced employees leaving? \n",
    "Dataset is from: https://www.kaggle.com/ludobenistant/hr-analytics\n",
    "Data visualization using Python packages: Numpy,Pandas,Seaborn,Plotly and Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplot\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load dataset\n",
    "hr = pd.read_csv('C:\\\\Users\\\\dxd4380\\\\Documents\\\\personal\\\\Programming samples\\\\Python\\\\1.Data Viz- HR Analytics\\\\HR_comma_sep.csv')\n",
    "#hr = pd.DataFrame.from_csv('../1.Data Viz- HR Analytics/HR_comma_sep.csv', index_col=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get preliminary view of data\n",
    "### Dataset contains 15000 samples with employees indicating if they left or not along with Nine(9)  data points describing their experience in the company. (Also called features/dimensions for machine learning purposes) \n",
    "\n",
    "### Understanding datatypes of various features \n",
    "** After looking at the data types and first few rows of data as shown below\n",
    "\n",
    "### Quantitative:\n",
    "* Continuous variables: satisfaction_level,last_evaluation,average_montly_hours\n",
    "* Discrete: number_project, time_spend_company\n",
    "\n",
    "### Qualitative:\n",
    "* Binary:Work_accident,left,promotion_last_5years\n",
    "* Unordered/Nominal: sales\n",
    "* Ordered/Ordinal: salary\n",
    "\n",
    "### *** To understand differences between different types of data, please read:\n",
    "http://blog.minitab.com/blog/understanding-statistics/understanding-qualitative-quantitative-attribute-discrete-and-continuous-data-types\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'float'>    14999\n",
      "Name: satisfaction_level, dtype: int64, <class 'float'>    14999\n",
      "Name: last_evaluation, dtype: int64, <class 'int'>    14999\n",
      "Name: number_project, dtype: int64, <class 'int'>    14999\n",
      "Name: average_montly_hours, dtype: int64, <class 'int'>    14999\n",
      "Name: time_spend_company, dtype: int64, <class 'int'>    14999\n",
      "Name: Work_accident, dtype: int64, <class 'int'>    14999\n",
      "Name: left, dtype: int64, <class 'int'>    14999\n",
      "Name: promotion_last_5years, dtype: int64, <class 'str'>    14999\n",
      "Name: sales, dtype: int64, <class 'str'>    14999\n",
      "Name: salary, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "#Check datatypes of features\n",
    "df = pd.DataFrame(hr)\n",
    "dtypeCount =[df.iloc[:,i].apply(type).value_counts() for i in range(df.shape[1])]\n",
    "print(dtypeCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  sales  \\\n",
       "0                   3              0     1                      0  sales   \n",
       "1                   6              0     1                      0  sales   \n",
       "2                   4              0     1                      0  sales   \n",
       "3                   5              0     1                      0  sales   \n",
       "4                   3              0     1                      0  sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic Logistic Regression\n",
    "Some data manipulation is performed before logistic regression. As you notice in the list of features and their data types, there are two features that are qualitative: Sales and Salary. Sales and Salary are converted into dummy variables. Accuracy scores of test and training datasets are close to 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'float'>    14999\n",
      "Name: satisfaction_level, dtype: int64, <class 'float'>    14999\n",
      "Name: last_evaluation, dtype: int64, <class 'int'>    14999\n",
      "Name: number_project, dtype: int64, <class 'int'>    14999\n",
      "Name: average_montly_hours, dtype: int64, <class 'int'>    14999\n",
      "Name: time_spend_company, dtype: int64, <class 'int'>    14999\n",
      "Name: Work_accident, dtype: int64, <class 'int'>    14999\n",
      "Name: left, dtype: int64, <class 'int'>    14999\n",
      "Name: promotion_last_5years, dtype: int64, <class 'str'>    14999\n",
      "Name: sales, dtype: int64, <class 'str'>    14999\n",
      "Name: salary, dtype: int64]\n",
      "0.802933333333\n",
      "0.792070406258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Initializing duplicate dataset without overwriting the original\n",
    "hr2=hr\n",
    "\n",
    "#Check datatypes of all columns in the parameters are compatible\n",
    "df = pd.DataFrame(hr)\n",
    "dtypeCount =[df.iloc[:,i].apply(type).value_counts() for i in range(df.shape[1])]\n",
    "print(dtypeCount)\n",
    "\n",
    "#Convert categorical variables into dummy variables\n",
    "\n",
    "hr_sales = pd.get_dummies(hr['sales'])\n",
    "hr2=pd.concat([hr2, hr_sales], axis=1)\n",
    "\n",
    "hr_salary = pd.get_dummies(hr['salary'])\n",
    "hr2=pd.concat([hr2, hr_salary], axis=1)\n",
    "\n",
    "#Build Target and parameters\n",
    "y = hr2['left'].values\n",
    "X = hr2.drop(['left','salary','sales'], axis=1).values\n",
    "\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(X,y,random_state=5,stratify=y)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))\n",
    "print(accuracy_score(clf.predict(Xlr), ylr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imbalanced data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.238133333333\n",
      "0.238065605832\n",
      "0.238082538836\n"
     ]
    }
   ],
   "source": [
    "uniquetest, countstest = np.unique(ytestlr,return_counts=True)\n",
    "testvals=dict(zip(uniquetest, countstest))\n",
    "print(\"test\":{},format(testvals[1]/len(ytestlr))\n",
    "\n",
    "uniquetrain, countstrain= np.unique(ylr,return_counts=True)\n",
    "trainvals=dict(zip(uniquetrain, countstrain))\n",
    "print(trainvals[1]/len(ylr))\n",
    "\n",
    "uniqueorig, countsorig= np.unique(y,return_counts=True)\n",
    "origvals=dict(zip(uniqueorig, countsorig))\n",
    "print(origvals[1]/len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the confusion matrix and classification report to understand the split between precision and recall. For the employees that left both the precision and recall are not very high. 0.64 precision means that quite a few employees that stayed were predicted as they left. 0.39 recall means that many employees that left were incorrectly classified as left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = clf.predict(Xtestlr)\n",
    "\n",
    "print(confusion_matrix(ytestlr, y_pred))\n",
    "print(classification_report(ytestlr, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best 'k', Model complexity curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Setup arrays to store train and test accuracies\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "# Loop over different values of k\n",
    "for i, k in enumerate(neighbors):\n",
    "    # Setup a k-NN Classifier with k neighbors: knn\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    knn.fit(Xlr, ylr)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(Xlr,ylr)\n",
    "\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[i] = knn.score(Xtestlr,ytestlr)\n",
    "\n",
    "# Generate plot\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add regularization/Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal Regularization paramter 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = [0.001, 0.1, 1, 10, 100,1000,10000]\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(Xlr, ylr)\n",
    "\n",
    "# Print the tuned parameters and scoreb\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best Training score is {}\".format(logreg_cv.best_score_))\n",
    "print(\"Best Test score is {}\".format(accuracy_score(logreg_cv.predict(Xtestlr), ytestlr)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(Xtestlr)[:,1] \n",
    "\n",
    "# Compute and print AUC score\n",
    "print(\"AUC: {}\".format(roc_auc_score(ytestlr, y_pred_prob)))\n",
    "\n",
    "# Compute cross-validated AUC scores: cv_auc\n",
    "cv_auc = cross_val_score(clf,X, y, cv=5,scoring ='roc_auc')\n",
    "\n",
    "# Print list of AUC scores\n",
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
